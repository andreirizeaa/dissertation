\documentclass[12pt,a4paper]{report}

% ============================================
% PACKAGES
% ============================================

% Encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Page layout
\usepackage[margin=2.5cm]{geometry}
\usepackage{setspace}
\onehalfspacing

% Graphics and figures
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\graphicspath{{figures/}}

% Tables
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{multirow}

% Math
\usepackage{amsmath}
\usepackage{amssymb}

% Code listings
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

% Hyperlinks
\usepackage[hidelinks]{hyperref}
\usepackage{url}

% Bibliography
\usepackage[
    backend=biber,
    style=authoryear,
    sorting=nyt,
    maxcitenames=2
]{biblatex}
\addbibresource{references.bib}

% Glossaries and acronyms
\usepackage[acronym,toc]{glossaries}
\makeglossaries

% Headers and footers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% Appendices
\usepackage[toc,page]{appendix}

% Gantt charts
\usepackage{pgfgantt}

% ============================================
% ACRONYMS
% ============================================

\newacronym{pb}{PB}{Pitch Book}
\newacronym{ib}{IB}{Investment Banking}
\newacronym{rag}{RAG}{Retrieval-Augmented Generation}
\newacronym{llm}{LLM}{Large Language Model}
\newacronym{vlm}{VLM}{Vision Language Model}
\newacronym{pm}{PM}{Precedent Material}
\newacronym{api}{API}{Application Programming Interface}
\newacronym{sdlc}{SDLC}{Software Development Lifecycle}
\newacronym{poc}{POC}{Proof of Concept}
\newacronym{hitl}{HITL}{Human-in-the-Loop}

% ============================================
% DOCUMENT INFO
% ============================================

\title{Compliance Aware, Agentic Pitch Book Generation For Bankers}
\author{Andrei Rizea}
\date{\today}

% ============================================
% DOCUMENT
% ============================================

\begin{document}

% --------------------------------------------
% FRONT MATTER
% --------------------------------------------

% Title Page
\begin{titlepage}
    \centering
    \vspace*{2cm}

    {\Huge\bfseries Compliance Aware, Agentic Pitch Book Generation For Bankers\par}

    \vspace{1cm}

    {\Large An all-in-one content generation tool providing agentic workflows with RAG search capabilities.\par}

    \vfill

    {\Large A Queen Mary Final Year Dissertation\par}

    \vspace{1cm}

    {\large\bfseries Andrei Rizea\par}
    {\large Student ID: 220300153\par}

    \vspace{1cm}

    {\large Supervised by: Manesha Peiris\par}

    \vspace{1cm}

    {\large Programme of Study:\par}
    {\large Digital \& Technology Solutions (Software Engineering)\par}

    \vspace{1cm}

    {\large Module: IOT635W\par}

    \vfill

    \vspace{1cm}

    {\large Queen Mary University of London\par}
    {\large \today\par}

\end{titlepage}

% Abstract
\begin{abstract}
\addcontentsline{toc}{chapter}{Abstract}
% TODO: Write abstract
\end{abstract}

% Acknowledgements
\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}
% TODO: Write acknowledgements

% Table of Contents
\tableofcontents
\listoffigures
\listoftables
\printglossary[type=\acronymtype,title=List of Acronyms]

% --------------------------------------------
% MAIN MATTER
% --------------------------------------------

\chapter{Introduction, Scope and Context}
\label{ch:introduction}

Knowledge workers in contemporary organisations spend a disproportionate fraction of their time not generating knowledge but searching for, reformatting, and repackaging existing knowledge assets \parencite{markus2001knowledge}. This observation, drawn from research into knowledge reuse in organisational settings, resonates with particular force in investment banking, where the production of client-facing presentation materials (commonly termed pitch books) consumes substantial analyst time despite the highly repetitive nature of these documents. This chapter establishes the problem context, situates the proposed solution within relevant literature, and defines the scope of this proof-of-concept implementation.

\section{The Cognitive Economics of Investment Banking}
\label{sec:cognitive-economics}

Investment banking represents a paradigmatic knowledge industry, with professional value derived primarily from analytical insight and client relationship management rather than physical output. Yet empirical evidence suggests a misallocation of cognitive resources within this sector. Industry surveys indicate that junior analysts dedicate between 50 and 70 percent of their working hours to document preparation activities, with pitch book creation representing a substantial component of this workload \parencite{cfi2025analyst, wso2024hours}. This allocation persists despite pitch books exhibiting high structural similarity: variations typically involve updated financial metrics, adjusted company names, and modified date ranges rather than fundamentally novel analytical frameworks.

The work of investment banking analysts divides into categories of markedly different cognitive demand. High-value activities include financial modelling, valuation analysis, due diligence investigation, and client advisory work. Lower-value but time-consuming activities encompass data gathering from disparate sources, formatting content to institutional templates, and iterative revision cycles addressing stylistic rather than substantive concerns. The current distribution of effort inverts what might be considered optimal from either a productivity or professional development perspective.

Radhakrishna and colleagues, investigating knowledge management processes in investment banking through structural equation modelling, found that organisations implementing robust knowledge management systems achieved productivity improvements of 20 to 25 percent \parencite{radhakrishna2024km}. Their research specifically identified document production workflows as presenting significant optimisation opportunities, particularly where repetitive processes could be augmented through intelligent automation while preserving the expert judgement essential to client-facing deliverables.

\section{Problem Analysis: Knowledge Reuse Barriers in Document Production}
\label{sec:problem-analysis}

The inefficiencies observable in pitch book production reflect broader challenges in organisational knowledge management that Markus characterised as knowledge reuse problems \parencite{markus2001knowledge}. Markus distinguished between different knowledge reuse situations, including shared work producers, shared work practitioners, expertise-seeking novices, and secondary knowledge miners, each presenting distinct barriers to effective reuse. Pitch book production involves elements of multiple categories: analysts reuse their own prior work, seek to leverage colleagues' precedent materials, and attempt to capture institutional knowledge embedded in historical documents.

Three interconnected barriers impede the realisation of this reuse potential. The first concerns the misallocation of cognitive resources described above. When analysts spend hours locating relevant precedent materials, extracting applicable sections, and reformatting content to current requirements, they engage in retrieval and transformation tasks that add minimal intellectual value. This time could alternatively support deeper analytical work or expanded client engagement.

The second barrier involves the erosion of institutional memory through inadequate knowledge codification. Knowledge management theory distinguishes between tacit knowledge (experiential understanding that resists explicit articulation) and explicit knowledge that can be documented and transmitted \parencite{dalkir2005km}. Pitch books represent attempts to codify analytical insights into explicit form, yet the institutional knowledge about effective pitch book construction, including template conventions, narrative structures, and persuasive framings, often remains tacit, residing in individual practitioners' experience rather than accessible repositories.

The third barrier relates to the friction inherent in transferring tacit knowledge to new practitioners. Each institution maintains distinctive approaches to pitch book construction, encompassing template designs, data sourcing procedures, narrative conventions, and quality expectations. Junior analysts must acquire this tacit knowledge through observation and iterative feedback, a process that extends onboarding periods and generates revision cycles that consume senior banker time. The absence of systematic knowledge capture mechanisms means this learning process repeats with each new cohort.

\section{Gap Analysis: The Evolution of Presentation Automation}
\label{sec:gap-analysis}

Research in automated presentation generation has progressed through distinct paradigms, each addressing different dimensions of the challenge. Early approaches, emerging around 2014, focused primarily on text-to-slide conversion, transforming written content into slide format through layout algorithms and content segmentation \parencite{zheng2025pptagent}. These systems prioritised content organisation over visual design, producing functional but aesthetically limited outputs. Subsequent developments introduced template-based generation, where predefined slide structures constrained output formatting, improving visual consistency at the cost of flexibility.

The recent PPTAgent framework advances beyond this paradigm by adopting an edit-based approach that analyses reference presentations to extract structural patterns, then applies these patterns to new content \parencite{zheng2025pptagent}. This represents a significant conceptual shift: rather than generating slides from abstract principles, the system learns from concrete examples. PPTAgent demonstrates superior performance across content quality, design coherence, and narrative structure compared to text-to-slide alternatives. The framework's evaluation methodology, employing both automated metrics and human assessment, establishes benchmarks applicable to domain-specific implementations.

However, PPTAgent and comparable systems target general presentation scenarios, leaving domain-specific requirements unaddressed. Investment banking pitch books involve specialised content types (financial tables, transaction comparables, market positioning charts) that generic systems handle inadequately. Furthermore, institutional template compliance represents a hard constraint in professional contexts that academic research has not prioritised. A pitch book that violates corporate visual identity standards fails regardless of content quality.

Commercial platforms offering AI-assisted presentation creation similarly address generic business contexts. These tools provide value for general corporate presentations but lack the domain knowledge, data integration capabilities, and template fidelity required for investment banking applications. The gap between available solutions and professional requirements creates the opportunity this project addresses.

Retrieval-Augmented Generation provides an architectural foundation for grounding generative outputs in authoritative knowledge sources \parencite{lewis2020rag}. By coupling large language models with retrieval mechanisms that surface relevant documents, RAG architectures reduce hallucination risks and improve factual accuracy. For pitch book generation, RAG offers potential for incorporating precedent materials, ensuring generated content aligns with institutional conventions and historical approaches. However, implementing effective retrieval requires substantial infrastructure for document processing, embedding generation, and similarity search; investments that may exceed proof-of-concept scope.

Agentic AI architectures extend these capabilities by enabling autonomous planning and execution of multi-step processes. Rather than responding to single prompts, agentic systems decompose complex tasks, invoke appropriate tools, and synthesise results \parencite{ibm2024agentic}. For pitch book generation, agentic approaches enable workflows that gather financial data from market sources, retrieve relevant precedent materials, generate content specifications, and assemble formatted outputs, all orchestrated without continuous human intervention. This aligns with the broader industry trajectory toward agentic enterprise systems \parencite{mckinsey2025agentic}.

The synthesis of these capabilities (template-aware generation, domain-specific data retrieval, and agentic orchestration) defines the technical approach this project explores. The novel contribution lies not in advancing any individual capability but in demonstrating their integration for a specific professional domain with stringent compliance requirements.

\section{Aims and Objectives}
\label{sec:aims-objectives}

This project aims to design, implement, and evaluate a proof-of-concept system demonstrating how AI-powered document generation can address knowledge reuse barriers in investment banking pitch book production while maintaining institutional template compliance.

From an organisational perspective, the aim is to demonstrate a workflow enabling analysts to generate substantive first drafts of pitch books through minimal input specification, reducing time allocation to document formatting while preserving human oversight of analytical content. This supports the broader objective of reallocating cognitive resources toward higher-value activities.

From an educational perspective, the aim is to investigate the technical integration of large language model orchestration with programmatic document generation, contributing understanding of how AI capabilities can be applied to professional document production contexts with specific compliance constraints.

These aims translate into five concrete objectives:

\begin{enumerate}
    \item Design and implement a template analysis component that programmatically extracts layout structures, colour palettes, font specifications, and placeholder configurations from reference PowerPoint files, enabling generated content to maintain visual consistency with institutional standards.

    \item Develop an agentic data retrieval layer that autonomously gathers company financials, market data, and regulatory filings from public sources including Yahoo Finance and SEC EDGAR, reducing manual data collection effort.

    \item Construct an LLM-powered content planning module that generates structured specifications for slide content, adapting output to different pitch book types while maintaining narrative coherence appropriate to investment banking conventions.

    \item Build a slide assembly component that maps planned content to extracted template structures, producing PowerPoint files that comply with institutional formatting requirements.

    \item Evaluate system outputs against metrics encompassing generation efficiency, template compliance, and content appropriateness, establishing baseline performance for future development.
\end{enumerate}

\section{Scope, Constraints and Success Criteria}
\label{sec:scope}

The project scope encompasses a functional proof of concept demonstrating the complete workflow from user input specification through formatted pitch book output. The system accepts deal context parameters (target company, transaction type, relevant date ranges), a reference template file, and pitch book type specification, producing a PowerPoint file populated with retrieved data and generated content structured according to the template design.

Several constraints define implementation boundaries. The agentic orchestration layer employs established frameworks rather than custom agent architectures, prioritising integration demonstration over novel agent development. Template analysis relies on programmatic extraction through python-pptx rather than vision-language model interpretation, deferring visual understanding capabilities to future work. Data sources are limited to publicly accessible APIs, excluding proprietary market data terminals that would be available in production contexts. Retrieval-Augmented Generation against precedent material repositories is designated as a stretch goal rather than core requirement, acknowledging the infrastructure investment this capability demands.

The project explicitly excludes real-time market data integration, production deployment infrastructure, and comprehensive regulatory compliance validation. These represent essential considerations for production systems but exceed proof-of-concept scope. Similarly, the system does not attempt to replace analyst judgement on deal positioning, valuation conclusions, or client-specific customisation; these remain firmly within human responsibility.

Success evaluation applies four criteria. First, the system should generate complete pitch book drafts within five minutes of input specification, demonstrating practical utility for workflow integration. Second, generated outputs should maintain template fidelity, with formatting, colours, and layouts matching reference files within assessable tolerances. Third, retrieved financial data should accurately reflect source information, with verification against manual retrieval establishing correctness baselines. Fourth, content structure should align with investment banking conventions, assessed through comparison with precedent examples and, where available, practitioner feedback.

Throughout, the system is designed for human-in-the-loop operation, producing drafts that support rather than supplant professional judgement. The objective is augmentation, enabling analysts to begin from substantive starting points rather than blank slides, not automation of the complete pitch book production process.

% --------------------------------------------
% SUBSEQUENT CHAPTERS (placeholders)
% --------------------------------------------

\chapter{Literature Review}
\label{ch:literature-review}

% TODO: Expand literature review

\chapter{Methodology and Project Plan}
\label{ch:methodology}

The successful delivery of a software engineering project requires systematic planning, appropriate methodology selection, and rigorous governance frameworks. This chapter details the development approach adopted, specifies both technical and business requirements, justifies technology selections through comparative analysis, presents the project schedule, and addresses risk management alongside ethical considerations. The methodology aligns with contemporary software engineering practices while accommodating the research dimensions inherent in a proof-of-concept investigation.

\section{Development Methodology}
\label{sec:dev-methodology}

Software development methodologies exist on a spectrum from plan-driven approaches such as Waterfall to adaptive approaches including various Agile frameworks \parencite{sommerville2016software}. The selection of an appropriate methodology depends on factors including requirements stability, project complexity, stakeholder availability, and team size. Table~\ref{tab:methodology-comparison} compares candidate methodologies against project-specific criteria.

\begin{table}[H]
\centering
\caption{Comparison of Development Methodologies}
\label{tab:methodology-comparison}
\begin{tabularx}{\textwidth}{|l|X|X|X|}
\hline
\textbf{Criterion} & \textbf{Waterfall} & \textbf{Scrum} & \textbf{Iterative Prototyping} \\
\hline
Requirements stability & Requires fixed requirements upfront & Accommodates changing requirements & Well-suited to evolving requirements \\
\hline
Feedback loops & Late feedback after implementation & Sprint reviews every 2-4 weeks & Continuous feedback through prototypes \\
\hline
Documentation & Extensive upfront documentation & Minimal, working software prioritised & Moderate, focused on design decisions \\
\hline
Risk management & Risks discovered late & Regular risk reassessment & Early risk identification through prototypes \\
\hline
Solo developer suitability & Moderate & Low (designed for teams) & High \\
\hline
Research integration & Poor & Moderate & Excellent \\
\hline
\end{tabularx}
\end{table}

This project adopts an \textbf{iterative prototyping methodology} informed by Agile principles. This selection reflects several project characteristics. First, requirements exhibit inherent uncertainty: the optimal approach to template analysis, content generation, and slide assembly cannot be fully specified prior to experimentation. Second, the project involves a single developer, rendering team-oriented ceremonies from Scrum inappropriate. Third, the research dimension necessitates flexibility to pursue promising directions discovered during implementation while abandoning approaches that prove ineffective.

The iterative approach structures development into cycles, each producing a functional prototype that demonstrates specific capabilities. Each iteration encompasses requirements refinement, design, implementation, and evaluation phases. Stakeholder feedback, from the academic supervisor and, where accessible, domain practitioners, informs subsequent iterations. This approach aligns with Beck's observation that software development benefits from embracing change rather than attempting to prevent it \parencite{beck2000extreme}.

Version control through Git provides the infrastructure for iterative development, enabling experimentation on feature branches while maintaining stable baselines. Continuous integration practices ensure that code quality is maintained throughout the development process, with automated testing validating functionality after each significant change.

\section{Requirements Analysis}
\label{sec:requirements}

Requirements specification establishes the contractual foundation for project evaluation. This section distinguishes business requirements addressing organisational value from functional and non-functional requirements specifying system behaviour and quality attributes respectively.

\subsection{Business Requirements}

Business requirements articulate the organisational value proposition that justifies project investment. For this proof-of-concept, business requirements derive from the knowledge management inefficiencies identified in Chapter~\ref{ch:introduction}:

\begin{enumerate}
    \item \textbf{BR1: Productivity Enhancement}: The system should demonstrate potential to reduce time spent on initial pitch book drafting by enabling generation of substantive first drafts from minimal input specification.

    \item \textbf{BR2: Knowledge Codification}: The system should capture institutional presentation conventions through template analysis, reducing dependence on tacit knowledge held by individual practitioners.

    \item \textbf{BR3: Quality Consistency}: Generated outputs should maintain consistent adherence to corporate visual identity standards, reducing revision cycles attributable to formatting inconsistencies.

    \item \textbf{BR4: Data Accuracy}: Financial data incorporated into generated pitch books should accurately reflect source information, supporting rather than undermining analyst credibility.
\end{enumerate}

\subsection{Functional Requirements}

Functional requirements specify discrete system capabilities. Table~\ref{tab:functional-requirements} presents requirements organised by system component, with priority classifications following MoSCoW conventions (Must have, Should have, Could have, Won't have).

\begin{table}[H]
\centering
\caption{Functional Requirements Specification}
\label{tab:functional-requirements}
\begin{tabularx}{\textwidth}{|l|l|X|l|}
\hline
\textbf{ID} & \textbf{Component} & \textbf{Requirement} & \textbf{Priority} \\
\hline
FR1 & Template Analyser & Extract slide layouts from reference .pptx files & Must \\
\hline
FR2 & Template Analyser & Identify colour palettes and font specifications & Must \\
\hline
FR3 & Template Analyser & Map placeholder positions and content types & Must \\
\hline
FR4 & Data Retrieval & Fetch company financials from Yahoo Finance API & Must \\
\hline
FR5 & Data Retrieval & Retrieve SEC filings via EDGAR API & Should \\
\hline
FR6 & Data Retrieval & Perform web searches for company news & Should \\
\hline
FR7 & Content Planner & Generate slide-by-slide content specifications & Must \\
\hline
FR8 & Content Planner & Adapt content structure to pitch book type & Must \\
\hline
FR9 & Content Planner & Maintain narrative coherence across slides & Should \\
\hline
FR10 & Slide Builder & Assemble slides matching template layouts & Must \\
\hline
FR11 & Slide Builder & Populate placeholders with generated content & Must \\
\hline
FR12 & Slide Builder & Generate charts from financial data & Could \\
\hline
FR13 & Orchestration & Coordinate multi-step generation workflow & Must \\
\hline
FR14 & Orchestration & Handle API failures gracefully & Should \\
\hline
FR15 & RAG Search & Query precedent material repository & Could \\
\hline
\end{tabularx}
\end{table}

\subsection{Non-Functional Requirements}

Non-functional requirements specify quality attributes constraining how the system delivers functionality. Table~\ref{tab:nonfunctional-requirements} presents requirements with measurable acceptance criteria where applicable.

\begin{table}[H]
\centering
\caption{Non-Functional Requirements Specification}
\label{tab:nonfunctional-requirements}
\begin{tabularx}{\textwidth}{|l|l|X|X|}
\hline
\textbf{ID} & \textbf{Category} & \textbf{Requirement} & \textbf{Acceptance Criterion} \\
\hline
NFR1 & Performance & System generates complete pitch book draft & Within 5 minutes of input submission \\
\hline
NFR2 & Performance & API response handling & Timeout after 30 seconds with graceful degradation \\
\hline
NFR3 & Reliability & System availability during demonstration & 95\% uptime during evaluation period \\
\hline
NFR4 & Usability & Input specification interface & Requires no technical expertise to operate \\
\hline
NFR5 & Maintainability & Codebase documentation & All public functions documented with docstrings \\
\hline
NFR6 & Maintainability & Code quality & Passes linting with no critical violations \\
\hline
NFR7 & Security & API credential management & No credentials in source code; environment variables used \\
\hline
NFR8 & Security & Input validation & All user inputs sanitised before processing \\
\hline
NFR9 & Compatibility & Output format & Valid .pptx files openable in Microsoft PowerPoint \\
\hline
NFR10 & Scalability & Concurrent users & Support single-user operation (POC scope) \\
\hline
\end{tabularx}
\end{table}

\section{Technology Stack}
\label{sec:technology-stack}

Technology selection balances multiple considerations including fitness for purpose, developer familiarity, ecosystem maturity, and long-term maintainability. This section justifies selections through comparative analysis against alternatives.

\subsection{Programming Language and Framework}

Python serves as the primary implementation language, selected for its dominance in AI/ML development and extensive library ecosystem. Table~\ref{tab:language-comparison} compares Python against alternatives.

\begin{table}[H]
\centering
\caption{Programming Language Comparison}
\label{tab:language-comparison}
\begin{tabularx}{\textwidth}{|l|X|X|X|}
\hline
\textbf{Criterion} & \textbf{Python} & \textbf{JavaScript/Node.js} & \textbf{Java} \\
\hline
AI/ML library support & Excellent (PyTorch, LangChain, OpenAI SDK) & Limited & Moderate \\
\hline
PowerPoint manipulation & python-pptx (mature) & Limited options & Apache POI (verbose) \\
\hline
Async capabilities & asyncio, FastAPI & Native (excellent) & Reactive streams (complex) \\
\hline
Development velocity & High & High & Moderate \\
\hline
Type safety & Optional (mypy) & Optional (TypeScript) & Strong \\
\hline
\end{tabularx}
\end{table}

FastAPI provides the backend framework, offering asynchronous request handling essential for managing concurrent API calls to external data sources. Its automatic OpenAPI documentation generation facilitates testing and future integration efforts.

\subsection{AI and LLM Integration}

The system leverages large language models for content planning and generation. Table~\ref{tab:llm-comparison} compares available options.

\begin{table}[H]
\centering
\caption{Large Language Model Comparison}
\label{tab:llm-comparison}
\begin{tabularx}{\textwidth}{|l|X|X|X|}
\hline
\textbf{Criterion} & \textbf{GPT-4/GPT-4o} & \textbf{Claude 3.5} & \textbf{Gemini Pro} \\
\hline
Structured output & Excellent (JSON mode) & Good & Good \\
\hline
Context window & 128K tokens & 200K tokens & 1M tokens \\
\hline
Function calling & Native support & Native support & Native support \\
\hline
Agent frameworks & OpenAI Agents SDK & Claude Agent SDK & LangChain integration \\
\hline
Cost efficiency & Moderate & Moderate & Good \\
\hline
\end{tabularx}
\end{table}

OpenAI's GPT-4o model serves as the primary LLM, selected for its robust structured output capabilities and mature agent framework support through the OpenAI Agents SDK. This framework enables tool-use patterns essential for the agentic data retrieval layer without requiring custom orchestration implementation.

\subsection{Data Sources and APIs}

External data retrieval employs publicly accessible APIs to avoid proprietary data licensing constraints. Table~\ref{tab:data-sources} summarises the data sources utilised.

\begin{table}[H]
\centering
\caption{External Data Sources}
\label{tab:data-sources}
\begin{tabularx}{\textwidth}{|l|X|X|l|}
\hline
\textbf{Source} & \textbf{Data Provided} & \textbf{Access Method} & \textbf{Rate Limits} \\
\hline
Yahoo Finance & Stock prices, financial statements, company profiles & yfinance Python library & Unofficial, fair use \\
\hline
SEC EDGAR & 10-K, 10-Q filings, company facts & REST API & 10 requests/second \\
\hline
Web Search & Company news, market commentary & SerpAPI or similar & Per subscription \\
\hline
\end{tabularx}
\end{table}

\subsection{Frontend and Deployment}

React with TypeScript provides the frontend framework, deployed via Vercel for simplified continuous deployment. The backend deploys on Render, offering managed Python hosting with automatic scaling capabilities. Supabase provides PostgreSQL database services with built-in authentication, though database utilisation remains minimal for this proof-of-concept scope.

\section{Project Plan}
\label{sec:project-plan}

The project timeline spans thirteen weeks from initiation to final submission, structured into phases aligned with the iterative methodology. Figure~\ref{fig:gantt-chart} presents the schedule as a Gantt chart, with dependencies indicated through sequential positioning.

\begin{figure}[H]
\centering
\begin{ganttchart}[
    hgrid,
    vgrid,
    x unit=0.55cm,
    y unit chart=0.6cm,
    title height=1,
    bar height=0.5,
    bar label font=\footnotesize,
    group label font=\footnotesize\bfseries,
    title label font=\footnotesize,
    milestone label font=\footnotesize,
    bar/.append style={fill=blue!40},
    group/.append style={fill=gray!40},
    milestone/.append style={fill=red!60}
]{1}{13}
\gantttitle{Project Timeline (Weeks)}{13} \\
\gantttitlelist{1,...,13}{1} \\

\ganttgroup{Planning \& Research}{1}{5} \\
\ganttbar{Project Setup}{1}{1} \\
\ganttbar{Intro \& Methodology}{1}{2} \\
\ganttbar{Literature Review}{3}{5} \\

\ganttgroup{Design \& Development}{4}{9} \\
\ganttbar{System Design}{4}{5} \\
\ganttbar{Template Analyser}{5}{6} \\
\ganttbar{Data Retrieval Layer}{6}{7} \\
\ganttbar{Content Planner}{7}{8} \\
\ganttbar{Slide Builder}{8}{9} \\
\ganttbar{Integration}{9}{10} \\

\ganttgroup{Testing \& Evaluation}{10}{12} \\
\ganttbar{Unit Testing}{10}{10} \\
\ganttbar{Integration Testing}{10}{11} \\
\ganttbar{User Evaluation}{11}{11} \\
\ganttbar{Evaluation Chapter}{11}{12} \\

\ganttgroup{Finalisation}{12}{13} \\
\ganttbar{Document Review}{12}{12} \\
\ganttbar{Final Edits}{13}{13} \\
\ganttmilestone{Submission}{13}

\end{ganttchart}
\caption{Project Gantt Chart (19th January -- 20th April 2026)}
\label{fig:gantt-chart}
\end{figure}

Table~\ref{tab:project-milestones} provides detailed milestone descriptions with specific deliverables and dates.

\begin{table}[H]
\centering
\caption{Project Milestones and Deliverables}
\label{tab:project-milestones}
\begin{tabularx}{\textwidth}{|l|l|X|X|}
\hline
\textbf{Phase} & \textbf{Date} & \textbf{Milestone} & \textbf{Deliverables} \\
\hline
1 & 19 Jan & Project Initiation & Repository setup, development environment configured \\
\hline
2 & 31 Jan & Documentation I & Introduction, Scope, Methodology chapters complete \\
\hline
3 & 21 Feb & Literature Review & Comprehensive literature review chapter complete \\
\hline
4 & 28 Feb & Design Complete & Architecture diagrams, API specifications, data models \\
\hline
5 & 14 Mar & Core Components & Template analyser and data retrieval functional \\
\hline
6 & 28 Mar & MVP Complete & End-to-end generation pipeline operational \\
\hline
7 & 4 Apr & Testing Complete & Unit and integration tests passing; evaluation data collected \\
\hline
8 & 11 Apr & Evaluation Complete & Results analysis and evaluation chapter written \\
\hline
9 & 18 Apr & Document Finalised & All chapters complete, proofread, formatted \\
\hline
10 & 20 Apr & Submission & Final report submitted via QMPlus \\
\hline
\end{tabularx}
\end{table}

\section{Risk Assessment and Mitigation}
\label{sec:risk-assessment}

Proactive risk management identifies potential threats to project success and establishes mitigation strategies. Table~\ref{tab:risk-assessment} presents the risk register with likelihood and impact assessments on a three-point scale (Low/Medium/High).

\begin{table}[H]
\centering
\caption{Risk Assessment and Mitigation Strategies}
\label{tab:risk-assessment}
\begin{tabularx}{\textwidth}{|l|X|l|l|X|}
\hline
\textbf{ID} & \textbf{Risk Description} & \textbf{Likelihood} & \textbf{Impact} & \textbf{Mitigation Strategy} \\
\hline
R1 & API rate limits restrict data retrieval during development & Medium & Medium & Implement caching; use mock data for testing; stagger API calls \\
\hline
R2 & LLM outputs inconsistent or hallucinated content & High & High & Structured output schemas; validation layers; human-in-the-loop review \\
\hline
R3 & Template analysis fails on complex slide layouts & Medium & High & Scope to common layouts; graceful degradation for unsupported elements \\
\hline
R4 & External API deprecation or changes & Low & High & Abstract API interactions; monitor changelogs; maintain fallback sources \\
\hline
R5 & Scope creep extends beyond POC boundaries & Medium & Medium & Strict MoSCoW prioritisation; regular scope reviews with supervisor \\
\hline
R6 & Technical complexity exceeds available time & Medium & High & Iterative delivery; prioritise core pipeline; defer stretch goals \\
\hline
R7 & Data accuracy issues undermine credibility & Medium & High & Verification against manual retrieval; source attribution in outputs \\
\hline
R8 & Generated outputs violate compliance requirements & Low & High & Human review mandatory; disclaimer on all outputs; no PII processing \\
\hline
\end{tabularx}
\end{table}

\section{Ethics, Data Governance and Compliance}
\label{sec:ethics}

Responsible AI development requires explicit consideration of ethical implications, data governance frameworks, and regulatory compliance. This section addresses these dimensions as they pertain to the project.

\subsection{Ethical Considerations}

The system operates as a productivity augmentation tool, explicitly preserving human agency in analytical judgements and client communications. Several ethical principles guide development:

\textbf{Transparency}: Generated content is clearly identified as AI-assisted, enabling recipients to apply appropriate scrutiny. The system does not attempt to disguise its outputs as human-authored.

\textbf{Accuracy}: Financial data retrieval prioritises accuracy over completeness. Where data quality cannot be assured, the system indicates uncertainty rather than presenting potentially incorrect information as authoritative.

\textbf{Human Oversight}: The human-in-the-loop design ensures that professionals review all outputs before client distribution. The system augments rather than replaces professional judgement.

\subsection{Data Governance}

Data governance addresses the collection, processing, storage, and retention of information within the system. Key principles include:

\textbf{Data Minimisation}: The system processes only data necessary for pitch book generation. User inputs are not retained beyond the generation session unless explicitly requested for precedent material purposes.

\textbf{Source Attribution}: All external data incorporated into generated outputs includes source attribution, enabling verification and supporting audit requirements.

\textbf{No Personal Data Processing}: The proof-of-concept explicitly excludes processing of personal identifiable information. Company data derives from public sources; no client-specific confidential information enters the system.

\subsection{Regulatory Compliance}

Financial services operate within stringent regulatory frameworks. While this proof-of-concept does not constitute a production system subject to full regulatory compliance, design decisions anticipate future requirements:

\textbf{AI Governance}: Emerging regulations including the EU AI Act establish requirements for AI systems in financial services \parencite{bis2024regulating}. The human-in-the-loop architecture aligns with requirements for human oversight of AI-assisted decision-making.

\textbf{Content Accuracy}: Financial promotion regulations require accuracy in client communications. The system's design as a draft generation tool (requiring human review before distribution) maintains compliance by preserving professional responsibility for final content.

\textbf{Audit Trail}: The system logs generation parameters and data sources, supporting potential audit requirements for understanding how specific outputs were produced.

\chapter{System Design}
\label{ch:system-design}

% TODO: System design content

\chapter{Implementation}
\label{ch:implementation}

% TODO: Implementation details

\chapter{Testing and Evaluation}
\label{ch:testing}

% TODO: Testing methodology and results

\chapter{Results and Discussion}
\label{ch:results}

% TODO: Present and discuss results

\chapter{Conclusion}
\label{ch:conclusion}

% TODO: Conclusions and future work

% --------------------------------------------
% BACK MATTER
% --------------------------------------------

% Bibliography
\printbibliography[heading=bibintoc]

% Appendices
\begin{appendices}

\chapter{Risk Assessment}
\label{app:risk-assessment}

% TODO: Include risk assessment table

\chapter{Project Plan}
\label{app:project-plan}

% TODO: Include Gantt chart or project timeline

\chapter{KSB Mapping}
\label{app:ksb-mapping}

% TODO: Map project to apprenticeship Knowledge, Skills, and Behaviours

\end{appendices}

\end{document}
